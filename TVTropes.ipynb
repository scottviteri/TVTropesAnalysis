{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Tropes\n",
    "## The stories underlying stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "#from ipywidgets import interact\n",
    "import re\n",
    "\n",
    "#import sklearn.datasets as datasets\n",
    "#import pandas as pd\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.externals.six import StringIO  \n",
    "#from IPython.display import Image\n",
    "#from IPython.display import display\n",
    "#from sklearn.tree import export_graphviz\n",
    "#import pydotplus\n",
    "\n",
    "import json\n",
    "import functools as ft\n",
    "\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we grab data\n",
    "\n",
    "## Original source\n",
    "https://old.datahub.io/dataset/dbtropes\n",
    "\n",
    "This is an rdf database. Since we are just looking at what movies have which tropes, we can us the database created here: https://arxiv.org/pdf/1809.10959.pdf. \n",
    "This has been imported into this project as all_films_and_their_tropes.json.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_films_and_their_tropes.json\",'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of 'data' is a dictionary from movie names to the names of their associated tropes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5925\n",
      "['ABeautifulMind', 'ABetterTomorrow', 'ABirdersGuideToEverything', 'ABittersweetLife', 'ABoyAndHisDog', 'ABridgeTooFar', 'ABronxTale', 'ACaseOfSpringFever', 'AChristmasCarol2009', 'AChristmasStory']\n",
      "['Foreshadowing', 'RuleOfPerception', 'AwardBaitSong', 'SoundtrackDissonance', 'PragmaticAdaptation', 'OffScreenTeleportation', 'ForegoneConclusion', 'ImaginaryFriend', 'OscarBait', 'TheReveal', 'IvyLeagueForEveryone', 'TakeAThirdOption', 'Hallucinations', 'AbsentMindedProfessor', 'TheLoinsSleepTonight', 'HollywoodNerd', 'ShoutOut', 'DoYouWantToCopulate', 'BrokenAce', 'TheBigBoard', 'SheIsAllGrownUp', 'PoliticallyCorrectHistory', 'AllThereIsToKnowAboutTheCryingGame', 'NotThatKindOfDoctor', 'RedScare', 'BunnyEarsLawyer', 'UnreliableNarrator', 'RoomFullOfCrazy', 'HollywoodScience', 'AdultFear', 'ForgetsToEat', 'SmartPeoplePlayChess', 'MeaningfulEcho', 'GoodWithNumbers', 'MentalStory', 'AnswerCut', 'NoMedicationForMe', 'EEqualsMCHammer', 'WritersCannotDoMath', 'EurekaMoment', 'EveryoneLovesBlondes', 'MadMathematician', 'WindmillCrusader', 'DitzyGenius', 'ScienceRelatedMemeticDisorder', 'BadassBoast', 'SchizoTech', 'OohMeAccentsSlipping', 'DumbassHasAPoint']\n",
      "\n",
      "DualTonfas\n",
      "18270\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(list(data.keys())[0:10])\n",
    "print(data['ABeautifulMind'])\n",
    "all_tropes = list(ft.reduce(lambda x,y: x.union(set(y)), data.values(), set()))\n",
    "all_movies = list(data.keys())\n",
    "\n",
    "print()\n",
    "print(all_tropes[0])\n",
    "print(len(all_tropes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are enough features that the data should not be represented as a (non-sparse) matrix. Instead, keep as a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5925, 18270)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "#from sklearn.cluster import KMeans\n",
    "import scipy.sparse as sp\n",
    "\n",
    "trope_to_num_dict = {v:i for i,v in enumerate(all_tropes)}\n",
    "def tropeToNum(v): \n",
    "    return trope_to_num_dict[v]\n",
    "\n",
    "movies_to_tropes = sp.dok_matrix((len(all_movies),len(all_tropes)), dtype=np.int8)\n",
    "\n",
    "for m in range(len(all_movies)):\n",
    "    tropes = data[all_movies[m]]\n",
    "    for i in map(tropeToNum, tropes):\n",
    "        movies_to_tropes[m, i] = 1\n",
    "    \n",
    "#movies_to_tropes = movies_to_tropes.transpose().tocsr()\n",
    "print(movies_to_tropes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a sparse representation, we still want to do a dimensionality reduction so that we can do clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {
    "308ca0cb7e5f4a60b80400c936b686f8": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "4914a264520e41b284509ff29d14e27c": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "4b8b9a3dba2c41d0a8e1aaa31fbca102": {
     "views": [
      {
       "cell_index": 78
      }
     ]
    },
    "8c47e9db89c84a56ae00f0c6448c30ce": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "90d101046d5b49b1ba10e7904c0cb29a": {
     "views": [
      {
       "cell_index": 70
      }
     ]
    },
    "b09022601cf64ee98f3b19a11e09f981": {
     "views": [
      {
       "cell_index": 79
      }
     ]
    },
    "bfb717b3463443c4b97d2e3976c61f5c": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "cdba7379088042cfa3899664e1c2bc34": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
